<!DOCTYPE html>

<html lang="en">

<head>

    <meta charset="UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Building Smarter Ways to Allocate Resources for Innovation in a Competitive World</title>

    <style>

        /* Basic Reset & Styling */

        * {

            margin: 0;

            padding: 0;

            box-sizing: border-box;

            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;

        }

        body {

            line-height: 1.6;

            color: #333;

            background-color: #f8f9fa;

            padding: 20px;

        }

        .container {

            max-width: 1200px;

            margin: 0 auto;

            background: white;

            padding: 40px;

            box-shadow: 0 0 20px rgba(0,0,0,0.1);

            border-radius: 8px;

        }

        /* Header Styles */

        header {

            text-align: center;

            margin-bottom: 40px;

            padding-bottom: 20px;

            border-bottom: 2px solid #eaeaea;

        }

        h1 {

            font-size: 2.5em;

            margin-bottom: 20px;

            color: #2c3e50;

        }

        .authors {

            font-size: 1.2em;

            margin-bottom: 15px;

            color: #7f8c8d;

        }

        .affiliations {

            font-style: italic;

            margin-bottom: 20px;

            color: #95a5a6;

        }

        .correspondence {

            font-size: 0.9em;

            color: #7f8c8d;

            margin-bottom: 10px;

        }

        /* Abstract Section */

        .abstract {

            background: #f8f9fa;

            padding: 25px;

            border-left: 4px solid #3498db;

            margin-bottom: 40px;

            border-radius: 4px;

        }

        .abstract h2 {

            color: #2c3e50;

            margin-bottom: 15px;

            font-size: 1.4em;

        }

        /* Main Content */

        section {

            margin-bottom: 40px;

        }

        h2 {

            color: #2c3e50;

            margin-bottom: 20px;

            padding-bottom: 10px;

            border-bottom: 1px solid #ecf0f1;

        }

        h3 {

            color: #34495e;

            margin: 25px 0 15px 0;

        }

        p {

            margin-bottom: 15px;

            text-align: justify;

        }

        ul, ol {

            margin: 15px 0;

            padding-left: 30px;

        }

        li {

            margin-bottom: 8px;

        }

        /* Figures */

        .figure {

            text-align: center;

            margin: 30px 0;

            padding: 20px;

            background: #f8f9fa;

            border-radius: 6px;

        }

        .figure img {

            max-width: 100%;

            height: auto;

            border: 1px solid #ddd;

        }

        .figure-caption {

            font-style: italic;

            margin-top: 10px;

            color: #7f8c8d;

        }

        /* Conclusion */

        .conclusion {

            background: #e8f4f8;

            padding: 25px;

            border-radius: 6px;

            border-left: 4px solid #2980b9;

        }

        /* Responsive */

        @media (max-width: 768px) {

            .container {

                padding: 20px;

            }

          

            h1 {

                font-size: 2em;

            }

          

            .abstract, .conclusion {

                padding: 15px;

            }

        }

    </style>

</head>

<body>

    <div class="container">

        <header>

            <h1>Building Smarter Ways to Allocate Resources for Innovation in a Competitive World</h1>

        </header>

        <section class="abstract">

            <h2>Abstract</h2>

            <p>

                This report proposes a logic-driven framework for resource allocation in innovation-driven economies, emphasizing motivational consistency from Christian Schubert's behavioral political economy. It highlights how U.S. over-regulation, often rooted in empathetic rather than logical measures, risks an economic crisis in AI by allowing China to advance faster. Drawing on historical cases like thorium reactors and current AI dynamics, the framework integrates mission-oriented investment, regulatory agility, and diffusion-model simulations to ensure efficient, long-term funding while preserving safety and Western leadership. This is a theoretical academic exploration—no real claims or affiliations.

            </p>

        </section>

        <section class="introduction">

            <h2>1 Introduction and Motivation</h2>

            <p>

                Across history, advances in energy and computing have hinged on decisive investments by governments and firms. The United States once pioneered thorium-fuelled molten-salt reactors at Oak Ridge National Laboratory (ORNL) in the 1960s, but the Atomic Energy Commission shifted funding to other technologies and terminated the molten-salt program in 1973. ORNL engineers believed that technical problems could be solved if support continued, yet budget priorities and regulatory inertia shelved the technology. Over fifty years later, China built on ORNL’s research and, in 2025, its TMSR-LF1 reactor achieved the first thorium-to-uranium fuel conversion, becoming the world’s only operating liquid-fuelled thorium molten-salt reactor. This milestone allows China to "breed" uranium from thorium, advancing toward energy independence and potentially powering ships for a decade on a single charge.

            </p>

            <p>

                The same pattern is visible in artificial intelligence (AI). Nvidia’s chief executive Jensen Huang told the Financial Times in November 2025 that “China is going to win the AI race.” He argued that China’s lower energy prices and looser regulations give its firms cheaper compute, whereas the West faces high energy costs and heavy regulation. Huang later clarified that China is only “nanoseconds behind” the United States, yet his warnings reveal a larger issue: access to abundant energy and permissive regulations can tilt innovation races. Predictions from ai-2027.com and experts such as Yoshua Bengio warn that, if compute scales ten-fold by 2027, superhuman AI could appear within two years, shifting geopolitical power.

            </p>

            <p>

                This proposal builds a logic-driven resource allocation framework that avoids the short-termism and regulatory stagnation that hindered past breakthroughs. It draws on behavioral political economy for motivational consistency, mission-oriented investment for bold public funding, and diffusion-model techniques to simulate and optimize investment decisions. The goal is to produce a transparent pipeline that aligns incentives, mobilises long-term R&D spending and ensures Western leadership in energy and AI while preserving safety and trust, in line with frameworks like the U.S. "America's AI Action Plan" from 2025.

            </p>

            <h3>1.1 The Role of Motivational Consistency: Insights from Christian Schubert</h3>

            <p>

                Christian Schubert's work in behavioral political economy emphasizes the importance of applying consistent motivational assumptions to both market and political behavior. In his survey, he argues that policymakers, like market agents, respond to incentives, and failing to recognize this leads to inefficient resource allocation.

            </p>

            <p>

                Due to the United States' over-regulatory practices, often driven by empathetic measures rather than purely logical ones, the nation risks a future economic crisis in AI. These regulations, while well-intentioned, slow innovation and allow China to advance faster with lighter regulatory practices, potentially giving them an upper hand in the AI race. The United States could beat them, but companies like Nvidia appear willing to assist China, as Jensen Huang's comments suggest a close competition where energy subsidies play a key role. If China gains the technology first, they could use it against everyone, posing existential risks given differing values on safety and control.

            </p>

        </section>

        <section class="background">

            <h2>2 Background: Evidence of Stagnation and Lessons from Past Cases</h2>

            <p>

                U.S. R&D Performance and Shifting Priorities

            </p>

            <p>

                The United States remains the world’s largest funder of research and development. In 2022 it performed $885.6 billion in R&D—a nominal 12 % increase over 2021—and its R&D intensity (R&D spending as a share of GDP) was 3.4 %, continuing a rise above 3 % since 2019. Business firms performed $692.7 billion (78 %) of this research, while higher education and the federal government contributed $91.4 billion and $73.3 billion respectively. Figure 1 illustrates the approximate upward trend in U.S. R&D spending, and Figure 2 shows the composition of performers in 2022.

            </p>

            <div class="figure">

                <img src="https://cdn.statcdn.com/Statistic/605000/609512-blank-754.png" alt="US R&D expenditure growth 2015-2022 line chart">

                <div class="figure-caption">

                    Figure 1: Approximate growth in total U.S. R&D expenditure between 2015 and 2022 (based on data from the National Science Foundation). Although the values are illustrative, they show the rising scale of R&D commitments.

                </div>

            </div>

            <div class="figure">

                <img src="https://files.taxfoundation.org/20221206181931/AM_RD_1.png" alt="US R&D performers composition 2022 pie chart">

                <div class="figure-caption">

                    Figure 2: Composition of U.S. R&D performers in 2022. Business firms dominate R&D spending, while universities and the federal government each contribute less than 11 %. These shares mirror the data reported by the National Science Foundation.

                </div>

            </div>

            <p>

                Despite high absolute spending, the composition of investment and regulatory environment can undermine innovation. Tyler Cowen notes that the Great Stagnation—a slowdown in productivity growth—coincided with a rising burden of regulation; he argues that increases in regulation, both good and bad, slow progress. Empirical research supports this view: a study summarised by MIT Sloan found that firms near regulatory thresholds (e.g., 50-employee threshold for additional labour rules) reduce innovation, and the resulting economic burden acts like a 2.5 % tax on profits that lowers aggregate innovation by roughly 5.4 %. Economist John Cochrane highlights a similar problem in the European Union, where burdensome carbon accounting rules and bureaucratic barriers create a drag of over regulation, leaving Europe’s integrated market roughly 30 % poorer per capita than the United States.

            </p>

            <p>

                The Thorium Reactor Experience

            </p>

            <p>

                During the 1960s, ORNL’s Molten Salt Reactor Experiment (MSRE) demonstrated that liquid fluoride salt could serve as a reactor fuel carrier. The broader molten-salt program was terminated in 1973 because the Atomic Energy Commission redirected resources to competing designs. The subsequent Molten Salt Breeder Reactor (MSBR) program was officially cancelled in 1976; a report from the Weinberg Foundation observes that the AEC cited budget constraints and chose to support liquid metal fast breeder reactors instead, despite ORNL’s confidence that technical challenges could be overcome.

            </p>

            <p>

                China’s TMSR-LF1 is built on U.S. research. The 2-megawatt prototype uses low-enriched uranium and contains about 50 kilograms of thorium. In October 2025, it successfully converted thorium into fissile uranium-233, making it the only operating example of a thorium-fuelled molten-salt reactor in the world. This breakthrough allows for "breeding" uranium from thorium, advancing China's path to energy independence. The project plans to scale up to a 100-MW demonstration by 2035, underscoring how earlier under-investment and regulatory caution allowed other nations to capitalise on U.S. intellectual capital.

            </p>

            <p>

                The AI Compute Race and Energy Dynamics

            </p>

            <p>

                The AI boom depends on massive compute and energy. Jensen Huang explained that Chinese developers enjoy significantly lower electricity prices because their government subsidises energy, whereas Western data centres face higher energy costs and stricter regulations. He contended that such advantages could make China “win the AI race,” though he later described the gap as mere nanoseconds. Meanwhile, AI-2027 forecasts suggest training compute could increase roughly ten-fold between 2023 and 2027, enabling models to surpass human coding ability by March 2027 and approach artificial general intelligence (AGI) soon after. Figure 3 visualises the projected growth in training compute.

            </p>

            <div class="figure">

                <img src="https://situational-awareness.ai/wp-content/uploads/2024/06/compute_long_run_trend_updated.png" alt="Projected AI training compute growth 2023-2027 line chart">

                <div class="figure-caption">

                    Figure 3: Projected growth in AI training compute relative to GPT-4. According to AI-2027 forecasts, compute could grow an order of magnitude by 2027, enabling superhuman performance.

                </div>

            </div>

            <p>

                Yoshua Bengio and other researchers have warned that the race for compute and unbridled deployment of AI systems carry enormous risks. Bengio argues that there is no known method to ensure that superhuman AI will behave as intended and calls for massive investment in AI safety, regulation and international treaties to prevent catastrophic misuse. Without such institutions, the rapid build-out of energy-hungry data centres could empower regimes that value control over openness. Recent 2025 frameworks like the U.S. "America's AI Action Plan" emphasize grid optimization and international cooperation to maintain leadership.

            </p>

        </section>

        <section class="theoretical-foundations">

            <h2>3 Theoretical Foundations</h2>

            <p>

                Motivational Consistency and Behavioral Political Economy

            </p>

            <p>

                Christian Schubert's work in behavioral political economy emphasizes the importance of applying consistent motivational assumptions to both market and political behavior. In his survey, he argues that policy makers—like firms—seek to maximise their utility (e.g., electoral success, agency budgets), and they respond to incentives. Ignoring this leads to “money grabs” and inconsistent decision-making when allocating public funds. Designing resource allocation rules thus requires aligning incentives across market and political actors.

            </p>

            <p>

                Mission-Oriented Investment and the State’s Role

            </p>

            <p>

                Economist Mariana Mazzucato emphasises that governments have historically driven radical innovation by taking mission-oriented risks. Her book “The Entrepreneurial State” notes that agencies such as DARPA and ARPA-E fund high-risk research, operate within the “risk space” and attract visionary talent. She argues that mission-oriented R&D is not about “picking winners” but about investing boldly in areas where private finance will not—defence, health, space, and green technology. Modern state investment banks, such as Brazil’s BNDES and China’s Development Bank, demonstrate how public finance can create markets when coupled with clear missions. A key lesson is that the state must remain patient, tolerating long horizons and failures while setting ambitious goals.

            </p>

            <p>

                Regulation, Stagnation and Incentives

            </p>

            <p>

                Evidence indicates that excessive regulation slows innovation. In addition to Cowen’s remarks on rising regulation and stagnation, studies show that regulatory thresholds reduce firms’ innovation rates and act like taxes on profits. Cochrane’s analysis of Europe illustrates how bureaucratic complexity and burdensome rules can impose a drag on economic performance. Together, these insights urge policy designers to balance legitimate safety and environmental goals against the need to facilitate experimentation and adoption of new technologies.

            </p>

            <p>

                Diffusion Models as a Metaphor and Tool

            </p>

            <p>

                Generative diffusion models exemplify how structured mathematical logic can transform randomness into meaningful outputs. Chieh-Hsin Lai and co-authors explain that diffusion models gradually add Gaussian noise to data using a Markov process (forward diffusion) and then train a neural network—often a U-Net—to reverse the process and denoise step by step. At each timestep, the model performs:

            </p>

            <p>

                x_t = \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon, \epsilon \sim N(0, I),

            </p>

            <p>

                where \beta_t controls the noise schedule. The reverse process learns to predict or remove the noise, effectively sampling from the data distribution. Diffusion models thus provide a metaphor for resource allocation: just as the forward process corrupts data into noise, a complex landscape of competing incentives and regulations can obscure the value of potential projects; the reverse denoising process is analogous to applying a structured, logic-driven rule to “extract” promising projects from the noise and allocate funds accordingly.

            </p>

        </section>

        <section class="proposed-pipeline">

            <h2>4 Proposed Innovation Allocation Pipeline</h2>

            <p>

                Building on the above, we propose a four-stage pipeline for smart resource allocation that ensures motivational consistency, encourages mission-oriented investment, and incorporates formal AI safety and diffusion-based simulations.

            </p>

            <p>

                1. Structure: Define Logical Rules and Incentives

            </p>

            <p>

                The first stage establishes transparent rules that determine eligibility and funding amounts. To achieve motivational consistency, political actors should be modeled as utility-maximising agents who respond to incentives. Rules should therefore:

            </p>

            <ul>

                <li>Use objective criteria: instead of discretionary grants, rely on metrics such as potential energy yield, emissions reduction per dollar, or compute-efficiency improvements.</li>

                <li>Tie rewards to performance milestones: projects continue receiving funds only if they meet milestones, aligning the incentives of developers with public objectives.</li>

                <li>Limit capture: institute conflict-of-interest disclosures and bidding processes to reduce rent-seeking and lobbying.</li>

            </ul>

            <p>

                2. Decision: Align Agents with Missions

            </p>

            <p>

                The second stage implements decision mechanisms that rank projects based on mission alignment and expected social returns. Mazzucato’s emphasis on mission-oriented investment suggests that governments should set clear goals—such as a carbon-neutral energy grid or safe AGI—and then solicit proposals to achieve them. Decision tools could include:

            </p>

            <ul>

                <li>Scoring functions that incorporate expected impacts, risk level, and alignment with national missions.</li>

                <li>Market-based auctions for compute resources or grants, with subsidies for safety-aligned outcomes. Auctions reveal the true cost of projects and discourage inflated budgets.</li>

                <li>Participatory panels with experts and citizen representation to ensure legitimacy and reflect diverse values.</li>

            </ul>

            <p>

                3. Policy: Build Institutions for Long-Term Funding and AI Safety

            </p>

            <p>

                Sustained investment requires institutional capacity. The U.S. should expand agencies like ARPA-E and create a dedicated AI Safety Agency. This stage includes:

            </p>

            <ul>

                <li>Long-term budgets: commit to funding programs for at least 10-15 years, reflecting the timelines needed for breakthroughs (as seen in the decades-long path from thorium research to deployment).</li>

                <li>Long-term budgets aligned with 2025 frameworks like the NIST AI Risk Management Framework or OECD AI Principles for governance.</li>

                <li>Long-term budgets: commit to funding programs for at least 10-15 years, reflecting the timelines needed for breakthroughs (as seen in the decades-long path from thorium research to deployment).</li>

                <li>International treaties and governance: heed Bengio’s call for global agreements on AI safety and robust regulation. Work with allies to set compute caps and enforce safety standards, preventing a race to the bottom.</li>

                <li>Regulatory agility: adopt sunset clauses and periodic reviews to retire obsolete rules. Ensure regulations incentivise innovation instead of imposing unnecessary compliance costs.</li>

            </ul>

            <p>

                4. Computation: Simulate and Optimize with AI Tools

            </p>

            <p>

                The final stage uses computational models to simulate outcomes and optimise funding portfolios. Diffusion models provide a flexible framework: starting from random initial allocations, one can simulate project returns with stochastic noise, then iteratively adjust allocations via a neural network to maximise an objective (e.g., social welfare). Such simulations could incorporate Monte-Carlo game theory, Bayesian networks, or reinforcement learning. The output helps policy makers explore “what-if” scenarios, identify robust strategies under uncertainty, and avoid over-reliance on human heuristics.

            </p>

        </section>

        <section class="case-studies">

            <h2>5 Case Studies</h2>

            <p>

                Thorium Reactor Revival

            </p>

            <p>

                Applying the proposed pipeline to thorium reactors, we would set a mission of building safe, proliferation-resistant molten-salt reactors. Structure rules might require proposals to show high breeding ratios or low waste; decision scores would prioritise scalability and cost per megawatt. A long-term funding institution could partner with universities and firms, drawing lessons from the TMSR-LF1 project but ensuring domestic control and safety. Diffusion-based simulations could explore scenarios of resource allocation across thorium and other next-generation reactor designs to find robust portfolios.

            </p>

            <p>

                The AI Compute Race

            </p>

            <p>

                For AI, the mission could be developing safe, energy-efficient AI systems. Structure rules could cap energy use per training run and require adherence to safety standards. Decision mechanisms might auction compute quotas, awarding subsidies to models that demonstrate formal safety proofs. On the policy side, establishing an AI Safety Agency and negotiating international compute agreements would prevent unregulated accumulation of compute in regimes with lower oversight. Diffusion-model simulations could evaluate the impact of different compute allocations on innovation and safety outcomes, helping policy makers decide when to subsidise hardware research (e.g., neuromorphic chips) versus algorithms, in line with 2025 guides like "AI for Public Resource Allocation."

            </p>

        </section>

        <section class="outcomes">

            <h2>6 Expected Outcomes and Impact</h2>

            <p>

                The proposed system offers several benefits:

            </p>

            <ul>

                <li>Aligned incentives: By recognising the self-interest of political actors, the system reduces rent-seeking and ensures that funds flow to projects that further public missions.</li>

                <li>Mission-oriented innovation: Clear goals and milestones, combined with patient capital, enable breakthroughs in energy and AI.</li>

                <li>Reduced stagnation: Simplified regulations and performance-based funding mitigate the drag of over-regulation, promoting innovative activity.</li>

                <li>AI safety and trust: By incorporating Bengio’s recommendations for formal safety and international governance, the framework ensures that AI advancements are aligned with democratic values.</li>

                <li>Evidence-based decisions: Simulation tools model uncertainty and complexity, enabling more robust allocation decisions than intuition alone.</li>

            </ul>

        </section>

        <section class="roadmap">

            <h2>7 Implementation Roadmap and Future Work</h2>

            <p>

                To operationalise this framework, policy makers should:

            </p>

            <ol>

                <li>Establish a task force combining economists, technologists, ethicists, and behavioural scientists to refine the scoring functions and rules.</li>

                <li>Pilot the system in a targeted domain (e.g., nuclear innovation or AI safety research) to evaluate its effectiveness. Collect data on project outcomes and adjust rules accordingly.</li>

                <li>Invest in computational infrastructure for running diffusion-based simulations, leveraging partnerships with cloud providers while enforcing safety measures.</li>

                <li>Engage international partners to harmonise safety standards and compute allocations, preventing a global arms race.</li>

            </ol>

            <p>

                Future research should expand on dynamic modelling of political incentives, integrate network effects (e.g., knowledge spillovers), and explore how the diffusion metaphor can be formalised for resource allocation algorithms. Additionally, researchers should investigate the interplay between energy policy and AI, exploring renewable energy sources (including thorium-based reactors) as enablers of AI compute that align with climate goals.

            </p>

        </section>

        <section class="discussion">

            <h2>Engage with the Ideas: Discussion Prompts</h2>

            <ul>

                <li>How might applying Christian Schubert's motivational consistency reduce rent-seeking in U.S. innovation funding, especially for high-risk projects like thorium reactors?</li>

                <li>In what ways could lighter regulations accelerate the AI race without compromising safety, drawing from Jensen Huang's warnings on energy costs?</li>

                <li>Could mission-oriented investment, as per Mariana Mazzucato, prevent historical stagnations like the thorium program's cancellation—what modern missions would you prioritize?</li>

                <li>Discuss the potential of diffusion models for simulating resource allocation: How might they balance behavioral biases in political decision-making?</li>

                <li>If China leads in AI due to "nanoseconds" advantages, what international treaties (inspired by Yoshua Bengio) could ensure Western values like openness prevail?</li>

                <li>How does over-regulation act as a "drag" on innovation, per Tyler Cowen and John Cochrane—examples from Europe or the U.S.?</li>

                <li>What role could behavioral political economy play in aligning incentives for AI safety, preventing a "race to the bottom"?</li>

                <li>Imagine reviving the Molten Salt Reactor Experiment today: What logical rules would you set for funding milestones?</li>

                <li>Does the Great Stagnation stem more from regulatory burdens or short-term political incentives—how to fix it for AGI timelines?</li>

                <li>How might stoic principles (e.g., Epictetus' control dichotomy) inform modern innovation policy in uncertain fields like compute scaling?</li>

            </ul>

        </section>

        <section class="conclusion">

            <h2>8 Conclusion</h2>

            <p>

                History shows that under-investment and regulatory inertia can squander early technological leadership. By building a logic-driven, incentive-consistent resource allocation system grounded in missions and informed by AI-enabled simulations, the United States and its allies can revitalise innovation, reclaim leadership in emerging energy technologies, and ensure that AI advances serve the public interest. The lessons from thorium reactors, the AI compute race, and the Great Stagnation emphasise the need for bold, mission-oriented investment and careful governance—principles that this proposal seeks to put into practice.

            </p>

        </section>

        <section class="references">

            <h2>References</h2>

            <ul>

                <li>Bengio, Yoshua. “Reasoning through Arguments against Taking AI Safety Seriously.” 9 July 2024, yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/.</li>

                <li>“Chinese Molten Salt Reactor Achieves Conversion of Thorium-Uranium Fuel.” World Nuclear News, 1 Nov. 2024, www.world-nuclear-news.org/articles/chinese-msr-achieves-conversion-of-thorium-uranium-fuel.</li>

                <li>China reaches energy independence milestone by 'breeding' uranium from thorium. SCMP, 3 Nov. 2025, www.scmp.com/news/china/science/article/3331312/china-reaches-energy-independence-milestone-breeding-uranium-thorium.</li>

                <li>Cochrane, John H. “Stagnation and Hope.” www.grumpy-economist.com/p/stagnation-and-hope.</li>

                <li>Endicott, Neil. “Report for the All Party Parliamentary Group on Thorium Energy: Thorium-Fuelled Molten Salt Reactors.” The Weinberg Foundation, June 2013, thoriumenergyalliance.com/wp-content/uploads/2020/02/WEINBERG-FOUNDATION-REPORT.pdf.</li>

                <li>Khan, Yasir. “Nvidia Boss Says China Will Win AI Race, Then Quickly Changes His Tune in Damage Control Scramble.” Newsneck, 6 Nov. 2025, newsneck.com/3499/nvidia-ceo-jensen-huang-china-ai-race/.</li>

                <li>Lai, Chieh-Hsin, et al. “The Principles of Diffusion Models: From Origins to Advances.” arXiv, 24 Oct. 2025, arxiv.org/pdf/2510.21890.pdf.</li>

                <li>Mayor, Tracy. “Does Regulation Hurt Innovation? This Study Says Yes.” MIT Sloan School of Management, mitsloan.mit.edu/ideas-made-to-matter/does-regulation-hurt-innovation-study-says-yes.</li>

                <li>Mazzucato, Mariana. “The Entrepreneurial State: Debunking Public vs. Private Myths in Risk and Innovation.” Anthem Press, 2013, crystalbook.ru/wp-content/uploads/2021/06/The-Entrepreneurial-State-Debunking-Public-vs.-Private-Myths-in-Risk-and-Innovation.pdf.</li>

                <li>Pethokoukis, James. “Tyler Cowen on the State of the Great Stagnation, Pro-Progress Policy, Metascience, and More!” American Enterprise Institute - AEI, 10 Feb. 2023, www.aei.org/articles/tyler-cowen-on-the-state-of-the-great-stagnation-pro-progress-policy-metascience-and-more/.</li>

                <li>Schnellenbach, Jan, and Christian Schubert. “Behavioral Political Economy: A Survey.” CESifo, Sept. 2014, www.ifo.de/DocDL/cesifo1_wp4988.pdf.</li>

                <li>Schubert, Christian, and Jan Schnellenbach. "A Note on the Behavioral Political Economy of Innovation Policy." Journal of Evolutionary Economics, vol. 29, no. 5, 2019, pp. 1399-1414.</li>

                <li>Schnellenbach, Jan. "A Behavioral Economics Perspective on the Entrepreneurial State and Mission-Oriented Innovation Policy." SSRN, 2023.</li>

                <li>Schubert, Christian. "What Do We Mean When We Say That Innovation and Entrepreneurship (Policy) Are Good Public Policy?" Journal of Economic Issues, vol. 49, no. 1, 2015, pp. 247-252.</li>

                <li>"America's AI Action Plan." The White House, July 2025, www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf.</li>

                <li>"9 Key AI Governance Frameworks in 2025." AI21 Labs, Aug. 2025, www.ai21.com/knowledge/ai-governance-frameworks/.</li>

                <li>"Global AI Governance: Five Key Frameworks Explained." Bradley, Aug. 2025, www.bradley.com/insights/publications/2025/08/global-ai-governance-five-key-frameworks-explained.</li>

                <li>"AI for Public Resource Allocation 2025 Guide." Rapid Innovation, 2025, www.rapidinnovation.io/post/ai-agent-public-policy-impact-analyzer.</li>

                <li>"Advancing Responsible AI Innovation: A Playbook." World Economic Forum, 2025, reports.weforum.org/docs/WEF_Advancing_Responsible_AI_Innovation_A_Playbook_2025.pdf.</li>

            </ul>

            <h3>Related Readings</h3>

            <p>For further exploration of the concepts discussed, consider these additional resources:</p>

            <ul>

                <li>Schubert, Christian, and Jan Schnellenbach. "A Note on the Behavioral Political Economy of Innovation Policy." Journal of Evolutionary Economics, vol. 29, no. 5, 2019, pp. 1399-1414. (Available at: ideas.repec.org/a/spr/joevec/v29y2019i5d10.1007_s00191-019-00625-y.html) – Demonstrates how behavioral political economy can address inefficiencies in innovation policy.</li>

                <li>Schnellenbach, Jan, and Christian Schubert. "Behavioral Political Economy: A Survey." CESifo Working Paper No. 4988, 2014. (Available at: www.ifo.de/en/cesifo/publications/2014/working-paper/behavioral-political-economy-survey) – Surveys the field and scope for further research in applying behavioral insights to politics.</li>

                <li>Schnellenbach, Jan. "A Behavioral Economics Perspective on the Entrepreneurial State and Mission-Oriented Innovation Policy." SSRN, 2023. (Available at: www.researchgate.net/publication/378132210_A_Behavioral_Economics_Perspective_on_the_Entrepreneurial_State_and_Mission-Oriented_Innovation_Policy) – Critiques mission-oriented policies through a behavioral lens, relevant to avoiding implementation pitfalls.</li>

                <li>Schubert, Christian. "What Do We Mean When We Say That Innovation and Entrepreneurship (Policy) Are Good Public Policy?" Journal of Economic Issues, vol. 49, no. 1, 2015, pp. 247-252. (Available at: www.tandfonline.com/doi/abs/10.1080/00213624.2015.1013859) – Reconstructs the normative basis for innovation policy.</li>

                <li>Nepal, Gopal. "Role of Political Economy in Mediating Innovation and Social Entrepreneurship." Semantic Scholar, 2019. (Available at: www.semanticscholar.org/paper/Role-of-Political-Economy-in-Mediating-Innovation-Nepal/0f8e1b2a0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b0b) – Analyzes political incentives in innovative behavior.

            </ul>

        </section>

    </div>

</body>

</html>
